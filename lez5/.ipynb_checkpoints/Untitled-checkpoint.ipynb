{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sampling Hydrogen Atom radius via Metropolis Algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these exercise, we aim to calculate $\\left<r\\right>$ for a hydrogen atom system, first of all in the $1s$ ground state, then in a $2p$ excited state. In order to do this, we have to sample the position probability for an electron, which is given by $\\left|\\Psi(r, \\theta, \\phi)\\right|^2$. We'll make use of natural units, i.e. $a_0=1$ (Bohr radius). This will prevent the risk of overflow when dealing with very small numbers (we're treating atomic distances, which can be very uncomfortable in S.I. units)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have to do is indeed generating a Markov chain: given a starting position $\\textbf{x}_0$, we want to produce a random walk, such that $\\textbf{x}_{i+1}$ choice must depend only from $\\textbf{x}_{i}$ position (the process is markovian, i.e. it has no memory of what's happened before $i$-th step). Furthermore, we want to simulate a stationary process, which means p(x) does not depend on time (and so $\\Psi(\\textbf{x})$ itself); all we wanto to do now is to generate $x_i$ steps according to our distribution probability $p(x)$, which is the squared modulus of $\\Psi(\\textbf{x}_i)$ for the hydrogen atom. Thus, we need to discard values $x_{i+1}$ with a lower probability respect to $p(x_i)$, otherwise we'll reduce our sampling to a trivial random walk: here Metropolis algorithm may help us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we define a trial transition probability $T(x_{i+1}|x_i)$ from $x_i$ to $x_{i+1}$ and an acceptance $A(x_{i+1}|x_i)$; usually, for Metropolis algorithm $A$ is defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A(x_{i+1}|x_i) = \\min\\left[1, \\frac{T(x_i|x_{i+1})p(x_{i+1})}{T(x_{i+1}|x_i)p(x_i)}   \\right]  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$T(x_{i+1}|x_i)$ can assume indeed whatever form, the balanced detail principle will be respected (that is, the probability $p(x)$ of being in $x$ is just the transition probability of coming to $x$ from all the other possible places $y$). However, a bad choice of $T$ will negatively influence our algorithm efficiency. Let's start with a constant trial probability $T=1$, in this case, we can develop our algorithm in the following way: first of all, generate a point $x_i$, then evaluate its probability $p(x_i)$. After that, generate a new point $x_{i+1}$ with its own probability $p(x_{i+1})$; generate a third value $r \\in [0;1]$, and proceed as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       if p(x[i+1])/p(x[i])>=r:\n",
    "          accept x[i+1]\n",
    "       else:\n",
    "          generate new x[i+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's explain how we've implemented the code (which is written in file main.cpp): let's call our starting coordinates $x,y$ and $z$: we'll assign them an opportune position close to the origin, otherwise the system will take a far too long time to equilibrate, with a remarkable risk of discard many values $x_{i+1}$ (this will mistify our average calculation of the radius). After that, we have to evaluate their distance from the origin, call it $r0$, and generate some new point $x_{new}, y_{new}$ and $z_{new}$ as $x_{new}=x+d*rdm$, where $d$ means the lenght of our increase, while rdm stands for the usual random number uniformly generated in $[0;1]$; we will call the new distance $r2$. Now, the acceptance probability for a $1s$ system will be defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$  A = \\min\\left[1, \\left|\\frac{e^{-r_1}}{e^{-r_0}}\\right|^2\\right] = \\min\\left[1, e^{2(r_0-r_1)}\\right] $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, if $e^{2(r_0-r_1)}>=rdm$, we'll accept our move, which means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "x_{new} \\rightarrow x \\\\\n",
    "y_{new} \\rightarrow y \\\\\n",
    "z_{new} \\rightarrow z \\\\\n",
    "r_1 \\rightarrow r_0 \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$r_1$, which is now in memory s $r_0$, will be saved in a vector V[M] (M the total number of steps, let's say $10^6$, and the next step will start from $x,y,z$ (the previous \"new\" variables). If instead $e^{r_0-r_1}<rdm$, we have to discard $x_{new},y_{new},z_{new}$, generating again new values from the previous $x,y$ and $z$; $r_0$ (which is always the old one) will be saved in our $V[M]$ vector instead of $r_1$. After we've filled V[M], we may proceed to average over $r$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same can be done for $2p$: the only difference lies in the probability function, which is now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\Psi(r, \\theta, \\phi) = C \\; r \\exp{\\left(-\\frac{r}{2}\\right)} \\cos(\\theta) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $C$ includes all costant factors. In $2p$ case, our acceptance will be given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\left(\\frac{r_1 \\cos(\\theta_1)}{r_0 \\cos(\\theta_0)}\\right)^2 \\exp{(r_0-r_1)} >= rdm $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replicate the same procedure from $1s$ to generate our Markov chain, we simply have a new probability: $\\theta$, in spherical coordinates, is defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\theta = \\cos^{-1}\\left(\\frac{z}{r}\\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes things much easier: inserting this definition of $\\theta$ in our probability acceptance we obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\left(\\frac{z_1}{z_0}\\right)^2 \\exp{(r_0-r_1)} >= rdm $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the procedure is just the same: if the new values are accepted, we save $r_1$ in our V[M] vector, and the new positions become the older (from which we generate the new ones), otherwise r_0 will fill our vector and we'll restart from the previous positions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: in order to follow the 50% empirical rule, set the lenght parameter $d$ and watch over your acceptance: we've found some optimal parameters $d=2$ for both $1s$ and $2p$ (we've declared $d$ with the label \"passo\" inside an input file, input.dat, which the main imports as the executable is launched). For blocking and plotting, we've exported our data in dati.csv file, then you have to run av.py script. Here some pictures of $\\left<r\\right>$ in natural units (expected values are marked by the red line) for $1s$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"graphs/r_1s.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and $2p$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"graphs/r_2p.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which fit perfectly with the expected values. In order to map $(x,y,z)$ positions during the simulation, we have saved some of these in dati_x.csv, dati_y.csv, dati_z.csv and then we proceeded with a scatterplot (whose script may be executed from script.py file):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"graphs/scattering_1s.png\" />\n",
    "for $1s$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"graphs/scattering_2p.png\" />\n",
    "for $2p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may run the code in script.py in order to reproduce these scatterplots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try now to generate our Markov chain with a gaussian probability. To do this, we've set an option in file input.dat: if you want to generate \"gaussian\" steps, you'll have to switch the so-called (by us) option variable at line 2 from 1 to 0; whenever you want to get back, you'll simply have to switch again option input variable from 0 to 1. Here some results from our new implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"graphs/r_1s_gauss.png\" />\n",
    "$1s$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"graphs/<r>_2p_gauss.png\" />\n",
    "$2p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
